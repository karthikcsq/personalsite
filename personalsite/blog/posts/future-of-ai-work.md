---
title: "On the Future of Work with AI"
date: "2025-09-16"
summary: "How AI will shape the future of work, and how humanity will actually achieve bigger and better."
---

## Why Write This?

I have been told, time and time again, that AI is going to allow humanity to accomplish more than they have before. There are naysayers to this claim, saying that AI will replace us completely. I don't fully buy that claim - yes, jobs will be replaced, but not humanity itself. Yet, those who claim that there will be higher productivity don't lay out concrete system by which AI will allow this for humanity.

In fact, there are a number of experts who have shared their views on the future of work and AI with the world. Yet, I have not been fully convinced that anything I heard will shape up to be true. Domething tells me that we will not be getting Artificial Superintelligence (ASI) or even AGI *by my definition* within the next 10 years (A bold claim within the AI community, for sure). Let me define what my perception of what AGI should be able to do, and explain why what others may consider AGI will not have the impacts claimed to exist.

Informally, AGI is the idea of a system that achieves equal knowledge and performance on any task to the best humans on the planet at that task. Many proponents of this idea will then go on to claim that, if AGI can be created, an ASI, or a system that achieves *better* knowledge and performance on any task than the best humans on the planet, will come shortly thereafter. Yet, even this claim is weak in the sense that it does not fully capture what humans truly excel at. While humans have been known to pursue knowledge and become skilled at specific cognitive tasks, the true journey that we as a civilization have been on, is vastly different than that of pursuing knowledge and improving at tasks. 

### The Betterment of Civilization

When humans first moved from being hunter-gatherers to a primarily agrarian society, there was a distinct change in the type of cognitive task that was performed. Humans went from being good at the repetitive cognitive task of hunting or gathering, to becoming more focused on the cognitive tasks required of growing food. The industrial revolution transfered this cognitive task to repetitively operating machinery, gaining domain expertise in that area correspondingly. 

Today, these tasks are distributed across thousands of different repetitive cognitive tasks. This is why people are worried about AI: it's really good at repetitive cognitive tasks. These are tasks that are not fully automatable with discrete operations (think McDonald's cashier), but require some information processing that affects what occurs (think data analyst). In essence however, we are using our brains as an information processing mechanism that maps some incoming information to a task that we have gained expertise in. When this information is clearly definable (an essay prompt, a coding task, data analysis, etc.), AI is very efficient at executing on a task from this information. 

This is why prompt engineering exists: AI works better when everything is clearly defined (and so do humans). This is also why plumbers and electricians are less scared of AI coming for their jobs - not simply because it's physical labor (although that is part of the reason), but rather, the input information space is messy. There's no clearly defined "language" that can be produced from chaotic physical systems yet. Hence, the models that we describe as AI, which are really Large *Language* Models, are vastly more ineffective in these scenarios. The success of AlphaFold can be attributed in large part to the development of a "language" for proteins, allowing it to iterate and test on a specifically defined set of information.

Yet, it is only recently in the history of humanity that we have developed clearly defined instruction sets for so many of the repetitive cognitive tasks that we perform today. This is the entire goal of the scientific method: define variable and collect measurable observations as a result. However, any scientist will tell you that it is not conducting the actual experiment that is difficult, but rather designing the experiment. Experiments that deal with real world materials, interactions, and complex systems are hard to design, because the wealth of decision that have to be made is simply incomprehensible to define clearly. But something about our minds and our experiences allow us to have grand visions of experiments and products that are not clearly defined, but still make use of these chaotic systems effectively.

Humans are not just good at repetitive cognitive tasks, but more importantly, we are better at taking in incomprehensible amounts of unclear, abstract, chaotic information, and using it to make decisions.

### So... why?

This is where my argument will weaken considerably, but I will attempt to make it nonetheless. I don't believe that the current models of AI will be able to make use of these chaotic real-world systems and design experiments from vague ideas. It will be able to plan and iterate and execute on experiments *easily*. The next Thomas Edison will no longer have to think of materials to build a lightbulb filament from, but rather, define the experiment that a lightbulb with a light-producing filament needs to exist to the AI clearly - and once this is done, the AI will iterate on elements, compounds, run experiments, and observe real data. It *feels* like AI is doing all our work for us, but really, this is grunt work. It is not the true intellectual pursuit or betterment of society that requires time spent by humans.

## The Future of Work

To make my argument, I will be initially approaching it from the lens of a software engineer, as that is the job I am most familiar with. When I speak with software engineers at big companies, I often am disappointed by the work that occurs. A team of 10 might be tasked with migrating a backend from one version of Java to the next to improve security. Another might be working on creating a slider to have continuous playback speeds on their videos rather than discrete ones. As much as it may pay, this is not where the advancements of humanity are made. Nor is it made within the purely data-driven standardized presentations of a consulting firm. These repetitive cognitive tasks are, frankly, below the calling of humanity. Yet, this is not also to say that a playback speed slider should not exist. On the contrary, there are users who undoubtedly benefited from this change in a small way, even if they did not specifically request or notice it.

What AI will truly change is the speed and efficiency at which we iterate on new ideas. Instead of a full team of 5 working for 2-3 months to build a new client portal, it will be accomplished by maybe 3 people in just a week or two. The grunt work of typing away at code and making sure everything is properly integrated will be sped up by auto-generated tests and code. A consulting agency will be able to have a smaller team think of sources of data that are important to a problem, and once it is collected, various metrics and patterns will be identified autonomously, allowing a solution to be discovered sooner. A research scientist will no longer need to precisely pipette - it will be done robotically. The research scientist can focus on defining groups of resources to test, stepping in when rare problems occur.

### Ideas and Projects

What I am proposing is a system by which workers no longer operate on these clearly defined, repetitive, cognitive tasks. Instead, we must be engines for ideas - not executors. We will develop a project economy, where new ideas are tested and implemented more rapidly than before, allowing us to always create that one extra thing in our lives that we wish existed but doesn't already. 

I'll describe this change with a simple example. In today's world, the CEO of a car company may want to launch a new product line of EVs that are similar to their existing EVs but offer more luxury and convenience features. This message will be passed down to VPs who may consider the design, the financial planning, the manufacturing, the market interest, the engineering, the software, the advertising, the safety, etc. This is then passed down to project managers who will work with subsections of each of these topics - under manufacturing, they may want to investigate building the new doors required by the car. Then, this will be passed down to more employees who might work with finances, design, raw materials suppliers, specific factories, to produce reports on different options and value it might bring to the product. This will eventually all come together over the course of years to produce this new EV.

In tomorrow's world, things will look different at first. The CEO will want to launch a new product line of EVs. The VPs will consider the same things as before. The project manager's work will be automatically broken down for them by an AI, which tells the project manager to look at doors. It will be their small team's responsibility to consider all the necessary objectives for the door - which the project manager's team does by defining to the AI what data to collect and process, and different ideas of potential factors to consider. The AIs will automatically work with agents from other teams to produce as many reports as necessary to reach a decision by the project manager's team - testing hundereds of designs, working with multiple budgets, and simulating thousands of factory lineups.

You're probably noticing something by now, which is that something happened to all the employees under the project manager. This is the where the great death of entry-level cognitive work is taking place right now - this is why you see so many programmers, data analysts, and technical writers worried about AI. As stated before, these repetitive cognitive tasks are where the initial displacement will occur.

### The Human Idea Machine

If there's one thing that we do know about work in human society, however, it's that we will not continue to simply remain jobless when technological advances change the nature of our work. The industrial revolution stripped millions of farming jobs, but all this did was move said jobs to factories. In similar fashion, the disappearance of repetitive cognitive work will result in this labor simply being shifted to a new type of work: idea generation.

Let us reimagine our car company CEO. In the future, the CEO will no longer be pent up thinking about any details regarding the style of the new EV that needs to be launched. That is, they will no longer consider the baseline or previous car iterations. This work will be left to the ideators - thinking of chassis and door designs that may not have been used by their cars before. Each idea can be overseen entirely by the team, including iteration, simulation, and optimization. So yes, while the grunt work of data gathering and information analysis may be displaced, the result will be a larger, flatter organization of ideators and project managers that are able to dynamically create and easily test projects within days or weeks.

## Closing Thoughts

All this being said, AI is *nowhere* near the level of operation as I have described it in this writing. It cannot even fathom the amount of unstructured data that gets processed daily by so many organizations and people. Yet, it is not a bold claim to say that this will change within 5-10 years. All we can do in the meantime is to prepare for this project-based future. Develop creativity - not just for the sake of creativity, but practical creativity that interacts with the world around us. Train your brain to constantly be producing ideas. My only hope is that the base claims I have made about the development and abilities of AGI remain consistent - otherwise, we may be in for the dystopian future many experts warn us about.